
<!DOCTYPE html>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./assets/analytics.js"></script>



    <title>Ricardo Martin-Brualla</title>

    <!-- Bootstrap core CSS -->
    <link href="./assets/bootstrap.min.css" rel="stylesheet">
    <link href="./assets/bootstrap-responsive.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="./assets/carousel.css" rel="stylesheet">
  <style id="holderjs-style" type="text/css">.holderjs-fluid {font-size:16px;font-weight:bold;text-align:center;font-family:sans-serif;margin:0}</style></head>

    <div class="container" style="important;margin-left:auto;margin-right:auto;margin-top:20px;">
<!--     <div class="container" style="width: 800px !important;margin-left:auto;margin-right:auto;margin-top:20px;"> -->
      <div style="padding:25px;background-color:white;border:1px solid #DDD;">
        <div style="overflow:hidden">
          <img src="./assets/me-320px.jpg" class="img-responsive" style="float: right">

          <h2>Ricardo Martin-Brualla</h2>


          <h4 style="margin-top:5px;margin-left:0.0em;">Contact: rmbrualla@gmail.com </h4>

          <p> Hi! I am Ricardo Martin-Brualla, and I do research at the intersection of Computer Vision, Computer Graphics and Machine Learning. I am interested in learning-based techniques that supplement existing 3D reconstruction pipelines to generate beautiful visuals.</p>

          <p>
          I work at Google in Seattle on the future of communication. In the fall of 2018, I taught Computer Vision at University of Washington. Previously, I obtained my PhD at <a href="http://www.cs.washington.edu/">Computer Science and Engineering</a> at the University of Washington under the supervision of <a href="http://homes.cs.washington.edu/~seitz/">Steve Seitz</a> and finished in June 2016. Before, I obtained undergraduate degrees in Math and Computer Science at <a href="https://www.upc.edu/en">Barcelona Tech / UPC</a>, as part of the interdisciplinary center <a href="https://cfis.upc.edu/ca">CFIS</a>. I grew up in Madrid, although I was schooled in the German high school system.
          </p>

          <p> I love traveling and seeing other parts of the world. After my undergraduate studies, I traveled by bicycle around New Zealand, visiting the antipodes of my house in Madrid. I also visited Vanuatu and climbed a volcano to see lava bubbling. After my PhD, I backpacked across Iceland, and explored Madagascar and Central Asia. I enjoy backcountry skiing and my latest challenge has been sea kayaking!
          </p>

          <p> In  2021, I spent 5 months crossing Alaska on foot and packraft with my wife. We wrote a blog about it: <a href="http://north2arctic.com/">north2arctic.com</a>. 
          </p>
        </div>        
                <div class="row-fluid" style="min-height:3px;max-height:3px; background-color:rgb(170,170,170);"> </div>

        <div class="row-fluid" style="min-height:3px;max-height:3px; background-color:rgb(170,170,170);"> </div>
        <div class="row-fluid" style="margin-top:0px;margin-bottom:10px;">
          <p></p><h3>Publications (<a href="https://scholar.google.com/citations?user=9F59OCYAAAAJ&hl=en&oi=ao">Google scholar</a>)</h3><p></p>

<table id="pubs">
    <tbody>



    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"><img class="teaser img-responsive" src="./assets/nerfies_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>Deformable Neural Radiance Fields</b></span><br>
        Keunhong Park, Utkarsh Sinha, Jonathan T. Barron, Sofien Bouaziz, Dan B Goldman, Steven M. Seitz, <b>Ricardo Martin-Brualla</b> <br>
        ICCV 2021 (oral). <br>
        [<a href="https://arxiv.org/pdf/2011.12948.pdf">paper</a>, <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA">video</a>, <a href="https://nerfies.github.io/">website</a>]
      </td>
    </tr>

    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"><img class="teaser img-responsive" src="./assets/nerfw_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections</b></span><br>
        <b>Ricardo Martin-Brualla*</b>, Noha Radwan*, Mehdi S. M. Sajjadi*, Jonathan T. Barron, Alexey Dosovitskiy, Daniel Duckworth <br>
        CVPR 2021 (oral). <br>
        [<a href="https://arxiv.org/pdf/2008.02268.pdf">paper</a>, <a href="https://www.youtube.com/watch?v=yPKIxoN2Vf0">video</a>, <a href="https://nerf-w.github.io/">website</a>]
      </td>
    </tr>


    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</b></span><br>
        Jonathan T. Barron, Ben Mildenhall, Matthew Tancik, Peter Hedman, Ricardo Martin-Brualla, Pratul P. Srinivasan <br>
        ICCV 2021 (oral). <br>
        [<a href="https://arxiv.org/pdf/2103.13415.pdf">paper</a>, <a href="https://jonbarron.info/mipnerf//">website</a>, <a href="https://github.com/google/mipnerf">code</a>]
      </td>
    </tr>

    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>IBRnet: Learning multi-view image-based rendering</b></span><br>
        Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul P Srinivasan, Howard Zhou, Jonathan T Barron, Ricardo Martin-Brualla, Noah Snavely, Thomas Funkhouser <br>
        CVPR 2021. <br>
        [<a href="https://arxiv.org/pdf/2102.13090.pdf">paper</a>, <a href="https://ibrnet.github.io/">website</a>, <a href="https://github.com/googleinterns/IBRNet">code</a>]
      </td>
    </tr>
        

    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>No Shadow Left Behind: Removing Objects and their Shadows using Approximate Lighting and Geometry</b></span><br>
        Edward Zhang, Ricardo Martin-Brualla, Janne Kontkanen, Brian L Curless <br>
        CVPR 2021. <br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_No_Shadow_Left_Behind_Removing_Objects_and_Their_Shadows_Using_CVPR_2021_paper.pdf">paper</a>, <a href="https://ed.ilogues.com/research/2020/12/21/no-shadow-left-behind-removing-objects-and-their-shadows-using-approximate-lighting-and-geometry/">website</a>]
      </td>
    </tr>


    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>Sharf: Shape-conditioned radiance fields from a single view</b></span><br>
        Konstantinos Rematas, Ricardo Martin-Brualla, Vittorio Ferrari <br>
        ICML 2021. <br>
        [<a href="https://arxiv.org/pdf/2102.08860.pdf">paper</a>, <a href="http://www.krematas.com/sharf/">website</a>]
      </td>
    </tr>



    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"><img class="teaser img-responsive" src="./assets/keystonedepth_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>KeystoneDepth: Visualizing History in 3D</b></span><br>
        Xuan Luo, Yanmeng Kong, Jason Lawrence, <b>Ricardo Martin-Brualla</b>, Steve Seitz <br>
        3DV 2020. <br>
        [<a href="https://drive.google.com/file/d/1IZUzIgVXypRIUdP5GsWXlQH85H4kSFJh/view">paper</a>, <a href="https://www.youtube.com/watch?v=nm2WYARNH1Q">video</a>, <a href="https://keystonedepth.cs.washington.edu/">website</a>]
      </td>
    </tr>



    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"><img class="teaser img-responsive" src="./assets/gelato_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>GeLaTO: Generative Latent Textured Objects</b></span><br>
        <b>Ricardo Martin-Brualla</b>, Rohit Pandey, Sofien Bouaziz, Matthew Brown, Dan B Goldman <br>
        ECCV 2020 (spotlight). <br>
        [<a href="https://gelato-paper.github.io/assets/gelato_eccv2020.pdf">paper</a>, <a href="https://www.youtube.com/watch?v=V68XHwRfAXQ">video</a>, <a href="https://gelato-paper.github.io/">website</a>]
      </td>
    </tr>


    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"><img class="teaser img-responsive" src="./assets/state_of_the_art_neural_rendering_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>State of the Art on Neural Rendering</b></span><br>
        Ayush Tewari, Ohad Fried, Justus Thies, Vincent Sitzmann, Stephen Lombardi, Kalyan Sunkavalli, <b>Ricardo Martin-Brualla</b>, Tomas Simon, Jason Saragih, Matthias Nießner, Rohit Pandey, Sean Fanello, Gordon Wetzstein, Jun-Yan Zhu, Christian Theobalt, Maneesh Agrawala, Eli Shechtman, Dan B Goldman, Michael Zollhöfer <br>
        EUROGRAPHICS 2020 (State of the Art Report). <br>
        [<a href="https://arxiv.org/pdf/2004.03805.pdf">paper</a>]
      </td>
    </tr>

    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"><img class="teaser img-responsive" src="./assets/multi_view_image_fusion_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>Multi-View Image Fusion</b></span><br>
        Marc Comino Trinidad, <b>Ricardo Martin-Brualla</b>, Florian Kainz, Janne Kontkanen <br>
        ICCV 2019 (poster). <br>
        [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Trinidad_Multi-View_Image_Fusion_ICCV_2019_paper.pdf">paper</a>]
      </td>
    </tr>

    <tr class="citationrow">
      <td class="teasertd" style="min-width:200px"><img class="teaser img-responsive" src="./assets/neural_rerendering_in_the_wild_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>Neural Rerendering in the Wild</b></span><br>
        Moustafa Meshry, Dan B Goldman, Sameh Khamis, Hugues Hoppe, Rohit Pandey, Noah Snavely, <b>Ricardo Martin-Brualla</b> <br>
        CVPR 2019 (oral). <b>Best Paper Award Finalist (top 1&#37; of submissions)</b><br>
        [<a href="https://arxiv.org/pdf/1904.04290.pdf">paper</a>, <a href="https://www.youtube.com/watch?v=E1crWQn_kmY">video</a>, <a href="https://github.com/google/neural_rerendering_in_the_wild">code</a>]
      </td>
    </tr>


    <tr class="citationrow">
      <td class="teasertd"><img class="teaser img-responsive" src="./assets/volumetric_capture_of_humans_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>Volumetric Capture of Humans with a Single RGBD Camera via Semi-Parametric Learning</b></span><br>
        Rohit Pandey, Anastasia Tkach, Shuoran Yang, Pavel Pidlypenskyi, Jonathan Taylor, <b>Ricardo Martin-Brualla</b>, Andrea Tagliasacchi, George Papandreou, Philip Davidson, Cem Keskin, Shahram Izadi, Sean Fanello
 <br>
        CVPR 2019 (poster).<br>
        [<a href="https://arxiv.org/pdf/1905.12162.pdf">paper</a>, <a href="https://www.youtube.com/watch?v=cbKE4av2NU4">video</a>]
      </td>
    </tr>

    <tr class="citationrow">
      <td class="teasertd"><img class="teaser img-responsive" src="./assets/lookingood_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>LookinGood: Enhancing Performance Capture with Real-time Neural Re-Rendering</b></span><br>
        <b>Ricardo Martin-Brualla*</b>, Rohit Pandey*, Shuoran Yang, Pavel Pidlypenskyi, Jonathan Taylor, Julien Valentin, Sameh Khamis, Philip Davidson,  Anastasia Tkach, Peter Lincoln, Adarsh Kowdle, Christoph Rhemann, Dan B Goldman, Cem Keskin, Steve Seitz, Shahram Izadi, Sean Fanello <br>
        Siggraph Asia 2018.<br>
        [<a href="https://arxiv.org/pdf/1811.05029.pdf">paper</a>, <a href="https://www.youtube.com/watch?v=Md3tdAKoLGU">video</a>]
      </td>
    </tr>
    <tr class="citationrow">
      <td class="teasertd"><img class="teaser img-responsive" src="./assets/seattle_timelapse_icon.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>Seattle 3 Year Time-lapse Video from the Space Needle</b></span><br>
        <b>Ricardo Martin-Brualla</b> <br>
        Hackernoon, 2018.<br>
        [<a href="https://hackernoon.com/seattle-3-year-time-lapse-video-from-the-space-needle-9a9e76cfe8bf">blog</a>, <a href="https://www.youtube.com/watch?v=-2MTiUGvqyE">video</a>, <a href="https://www.youtube.com/watch?v=NDtj1p0x31c">make-of</a>] <br>
        <span style="color:red">Press: </span> <a href="https://www.seattletimes.com/seattle-news/time-lapse-video-shot-over-three-years-atop-the-space-needle-reveals-seattles-astounding-growth/">Seattle Times</a>, <a href="https://petapixel.com/2018/01/09/3-year-timelapse-shows-quickly-seattle-evolved/">PetaPixel</a>, <a href="https://www.geekwire.com/2018/rapid-rise-new-seattle-time-lapse-video-shot-3-years-captures-citys-massive-growth/">GeekWire</a><br>
        <span style="color:red">More than 500k views on Youtube!</span>
      </td>
    </tr>
    <tr class="citationrow">
      <td class="teasertd"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>3D Time-lapse Reconstruction from Internet Photos</b></span><br>
        <b>Ricardo Martin-Brualla</b>, David Gallup, Steven M. Seitz <br>
        International Journal on Computer Vision (IJCV) 2017.<br>
        [<a href="https://dl.acm.org/citation.cfm?id=3158451">paper</a>]
      </td>
    </tr>

    <tr class="citationrow">
      <td class="teasertd"><img class="teaser img-responsive" src="./assets/iccv15_thumb.jpg"></td>
      <td class="citation2">
        <span style="font-size:12pt"><b>3D Time-lapse Reconstruction from Internet Photos</b></span><br>
        <b>Ricardo Martin-Brualla</b>, David Gallup, Steven M. Seitz <br>
        International Conference on Computer Vision (ICCV 2015) (oral presentation).<br>
        [<a href="http://grail.cs.washington.edu/projects/timelapse3d/3DTimelapseReconstructionICCV15.pdf">paper</a>, <a href="http://grail.cs.washington.edu/projects/timelapse3d">project page</a>, <a href="https://www.youtube.com/watch?v=oQpq4TM96Ow">video</a>] <br>
        <span style="color:red">Press: </span> <a href="http://petapixel.com/2015/12/12/scientists-create-3d-time-lapse-videos-from-internet-photos-of-landmarks/">PetaPixel</a>
      </td>
    </tr>
    <tr class="citationrow">
                <td class="teasertd"><img class="teaser" src="./assets/timelapse_icon.jpg" width="120"></td>
                <td class="citation2">
      <span style="font-size:12pt"><b>Time-lapse Mining from Internet Photos</b></span><br>
      <b>Ricardo Martin-Brualla</b>, David Gallup, Steven M. Seitz <br>
      Proceedings of ACM SIGGRAPH 2015.<br>
      [<a href="http://grail.cs.washington.edu/projects/timelapse/TimelapseMiningSIGGRAPH15.pdf">paper</a>, <a href="http://grail.cs.washington.edu/projects/timelapse">project page</a>, <a href="https://www.youtube.com/watch?v=wptzVm0tngc">video</a>] <br>
      <span style="color:red">Press: </span> interviews at <a href="http://www.wired.com/2015/05/crowdsourced-timelapse/">WIRED</a>, <a href="http://www.bbc.com/news/technology-32803455">BBC</a>, <a href="http://www.seattletimes.com/business/technology/uw-students-show-off-computer-science-expertise/">Seattle Times</a> and featured in <a href="http://www.washingtonpost.com/news/morning-mix/wp/2015/05/18/how-researchers-turned-the-chaos-of-millions-of-flickr-images-into-beautiful-time-lapses/">Washington Post</a>, <a href="http://gizmodo.com/google-creates-amazing-timelapses-from-photo-mining-pub-1705188634">Gizmodo</a>, <a href="http://www.cnet.com/news/google-researchers-use-86-million-photos-to-create-time-lapse-videos/">CNET</a>, etc. <br>
      <span style="color:red">More than 1.5 million Youtube views!</span>
                </td>
    </tr>
    <tr class="citationrow">
      <td class="teasertd"><img class="teaser" src="./assets/eccv2014_icon.jpg"></td>
      <td class="citation2">
      <span style="font-size:12pt"><b>The 3D jigsaw puzzle: mapping large indoor spaces</b></span><br>
      <b>Ricardo Martin-Brualla</b>, Yanling He, Bryan C. Russell, Steven M. Seitz. <br>
      Proceedings of the 13th European Conference on Computer Vision, (ECCV 2014).<br>
      [<a href="http://grail.cs.washington.edu/projects/jigsaw3d/ECCV2014_3d_jigsaw_puzzle.pdf">paper</a>, <a href="http://grail.cs.washington.edu/projects/jigsaw3d">project page</a>, <a href="https://www.youtube.com/watch?v=CRRhyhaI7zY">video</a>]
      </td>
      </tr>
      <tr class="citationrow">
      <td class="teasertd"><img class="teaser" src="./assets/siggraphasia2013_icon.jpg"></td>
      <td class="citation2"><span style="font-size:12pt"><b>3D Wikipedia: Using Online Text to Automatically Label and Navigate Reconstructed Geometry</b></b><br>
      Bryan C. Russell, <b>Ricardo Martin-Brualla</b>, Daniel J. Butler, Steven M. Seitz, and Luke Zettlemoyer.<br>ACM Transactions on Graphics (SIGGRAPH Asia 2013), Vol. 32, No. 6.<br>
      [<a href="http://grail.cs.washington.edu/projects/label3d/3D_Wikipedia_SIGGRAPH_Asia_2013.pdf">paper</a>, <a href="http://grail.cs.washington.edu/projects/label3d">project page</a>, <a href="https://www.youtube.com/watch?v=CNWFZzmZ0as">video</a>]<br>
      <span style="color:red">Press: </span> <a href="http://www.newscientist.com/article/dn24318-take-virtual-3d-tours-of-tourist-sites-with-wikipedia.html">New Scientist</a>, <a href="http://www.newscientist.com/article/dn24318-take-virtual-3d-tours-of-tourist-sites-with-wikipedia.html">Gizmodo</a>
      </td>
      </tr>
    <tr class="citationrow">
    <td class="teasertd"><img class="teaser" src="./assets/ieee_multimedia_2013_icon.jpg"><br></td>
    <td class="citation2">
    <span style="font-size:12pt"><b>Viewport: A Fully Distributed Immersive Teleconferencing System with Infrared Dot Pattern</b></span><br>
Cha Zhang, Qin Cai, Phillip Chou, Zhengyou Zhang, <b>Ricardo Martin-Brualla</b> <br>
IEEE Multimedia Magazine, pp. 17-27, Vol. 20, No. 1, Jan.-Mar. 2013. <br>
 [<a href="./assets/ieee_multimedia_2013.pdf">paper</a>]
    </td></tr><tr class="citationrow">
    <td></td>
    <td class="citation2"><span style="font-size:12pt"><b>Instance Sense Induction from Attribute Sets</b></span><br>
<b>Ricardo Martin-Brualla</b>, Enrique Alfonseca, Marius Pasca, Keith Hall, Enrique Robledo-Arnuncio, Massimiliano Ciaramita<br>
Proceedings of the 23rd International Conference on Computational Linguistics: Posters (COLING-2010), pp. 819-827 <br>
    [<a href="./assets/coling_2010.pdf">paper</a>]
    </td>
    </tr>
    <tr class="citationrow">
    <td></td>
    <td class="citation2">
    <span style="font-size:12pt"><b>The Role of Query Sessions in Extracting Instance Attributes from Web Search Queries</b></span><br>
    Marius Pasca, Enrique Alfonseca, Enrique Robledo-Arnuncio, <b>Ricardo Martin-Brualla</b>, Keith Hall.<br>
Proceedings of the 32nd European Conference on Information Retrieval (ECIR-2010), pp. 62-74.<br> 
    [<a href="./assets/ecir_2010.pdf">paper</a>]

    </td></tr>
  </tbody></table>

        <div class="row-fluid" style="min-height:3px;max-height:3px; background-color:rgb(170,170,170);"> </div>
      </div>
    </div>


    <script src="./assets/jquery.js"></script>
    <script src="./assets/bootstrap.min.js"></script>
    <script src="./assets/holder.js"></script>
<script>
  ga('create', 'UA-44456641-1', 'washington.edu');
  ga('send', 'pageview');
</script>
  

</div></body></html>
